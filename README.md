# ğŸŒŸ LangChain Character Extractor

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![LangChain](https://img.shields.io/badge/LangChain-RAG-green)
![MistralAI](https://img.shields.io/badge/MistralAI-LLM-orange)
![ChromaDB](https://img.shields.io/badge/VectorDB-Chroma-purple)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

A fully functional **RAG (Retrieval-Augmented Generation)** pipeline that extracts **structured character information** from story documents using:

- ğŸ§  **MistralAI** models  
- ğŸ” **Semantic Vector Search (ChromaDB)**  
- ğŸª„ **LangChain** orchestration  
- ğŸ“ **Strict JSON extraction**  
- ğŸ”’ **Anti-hallucination guardrails**  

---

# ğŸ“¦ Features at a Glance

| Feature | Description |
|--------|-------------|
| ğŸ” Vector Retrieval | Finds relevant story segments using embeddings |
| ğŸ“š RAG Pipeline | Retrieval â†’ Augmentation â†’ LLM Generation |
| ğŸ§± Structured Output | Name, summary, relations, character type |
| ğŸ¤– Mistral LLM | Extraction with strict JSON |
| ğŸš« Anti-Hallucination | Rejects non-human entities and false matches |
| ğŸ§ª Edge Case Handling | Clean errors for missing characters |
| ğŸ›  CLI Tools | Easy to run and test |

---

# ğŸ§  Why This Is a RAG System

RAG = **Retrieve + Augment + Generate**

Traditional LLMs cannot answer questions about documents they haven't seen.  
This system solves that via:

1. **Embed stories** into vector space (`mistral-embed`)
2. **Store embeddings** in ChromaDB
3. **Retrieve relevant segments** using semantic search
4. **Augment LLM input** with only the top relevant chunks
5. **Generate structured JSON** using an LLM (open-mistral-7b)

---

# ğŸ—‚ System Architecture (ASCII Diagram)

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚        Story Files      â”‚
                   â”‚        (data/*.txt)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Text Splitter         â”‚
                   â”‚ (RecursiveCharacter...) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Mistral Embeddings    â”‚
                   â”‚     (mistral-embed)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     ChromaDB       â”‚
                     â”‚ (Vector Database)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                 Query: "John" â”‚
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Semantic Retrieval     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  LLM Augmented Prompt   â”‚
                   â”‚ (strict JSON schema)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Mistral LLM Output    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ Project Structure

```
langchain-character-extractor/
â”‚â”€â”€ data/                       # Story files
â”‚â”€â”€ chroma_db/                  # Vector DB (auto-created)
â”‚â”€â”€ compute_embeddings.py       # Builds embeddings and DB
â”‚â”€â”€ get_character_info.py       # RAG pipeline for character extraction
â”‚â”€â”€ cli.py                      # User-friendly CLI
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .env.example
â”‚â”€â”€ .gitignore
```

---

# âš™ï¸ Installation

```bash
git clone https://github.com/AlankarJagtap/langchain-character-extractor
cd langchain-character-extractor
pip install -r requirements.txt
cp .env.example .env
```

Add your API key:

```
MISTRAL_API_KEY=your_api_key_here
```

---

# ğŸš€ Usage

### 1ï¸âƒ£ Compute Embeddings

```bash
python cli.py compute-embeddings --data-dir data --persist-dir chroma_db
```

### 2ï¸âƒ£ Extract Character Information

```bash
python cli.py get-character-info "Alice"
```

---

# ğŸ§ª Example Output

```json
{
  "name": "John Spatter",
  "storyTitle": "David Copperfield",
  "summary": "...",
  "relations": [
    {"name": "Michael", "relation": "business partner"}
  ],
  "characterType": "side character"
}
```

---

# ğŸ›‘ Edge Case Handling

### âŒ Character not found
```json
{ "error": "Character 'X' not found in any story." }
```

### âŒ Non-human term
```json
{ "error": "Not a character in the story." }
```

### âŒ Invalid JSON
Shows LLM output for debugging.

---

# ğŸ¯ Summary

This project demonstrates:

- A **full RAG pipeline**
- Clean abstraction layers  
- Accurate retrieval via embeddings  
- Real-world structured LLM extraction  
- Robust error handling  
- Practical application of LangChain + MistralAI  

Perfect for interviews, assignments, and demonstrating knowledge of applied RAG systems.

---

ğŸ“ **Author:** Alankar Jagtap  
ğŸ”— GitHub: https://github.com/AlankarJagtap
